In this section, we present our methodology for constructing CVGlobal, a large-scale multi-modal dataset that pairs satellite and street-view imagery across diverse global regions. Our approach systematically samples locations from five continents while ensuring geographical diversity and balanced representation between urban and rural environments.

\subsection{Dataset Design and Sampling Strategy}

Our dataset construction methodology is guided by three key principles: \textit{geographical diversity}, \textit{balanced representation}, and \textit{multi-modal consistency}. We define sampling regions across five major continents (North America, Europe, Asia, South America, and Africa), with each continent contributing equally to the final dataset to prevent geographical bias.

For each continent, we establish two distinct sampling regions:
\begin{itemize}
    \item \textbf{Urban regions}: Areas with high population density and significant urban infrastructure
    \item \textbf{Rural regions}: Areas with low population density and predominantly natural or agricultural landscapes
\end{itemize}

The sampling regions are carefully selected to represent diverse climatic, cultural, and developmental contexts within each continent. Table~\ref{tab:sampling_regions} details the specific geographical boundaries for each region.

\begin{table}[t]
\centering
\caption{Geographical sampling regions defined for each continent and environment type.}
\label{tab:sampling_regions}
\begin{tabular}{lllcc}
\toprule
\textbf{Continent} & \textbf{Type} & \textbf{Location} & \textbf{Lat Range} & \textbf{Lon Range} \\
\midrule
North America & Urban & New York City & 40.71°--40.81°N & 74.01°--73.91°W \\
              & Rural & California Farmland & 36.78°--36.88°N & 119.42°--119.32°W \\
\midrule
Europe & Urban & Paris & 48.86°--48.96°N & 2.35°--2.45°E \\
       & Rural & French Countryside & 46.23°--46.33°N & 2.21°--2.31°E \\
\midrule
Asia & Urban & Tokyo & 35.69°--35.79°N & 139.69°--139.79°E \\
     & Rural & Rural India (Agra) & 27.18°--27.28°N & 78.04°--78.14°E \\
\midrule
South America & Urban & São Paulo & 23.55°--23.45°S & 46.63°--46.53°W \\
              & Rural & Brazilian Rainforest & 14.24°--14.13°S & 51.93°--51.83°W \\
\midrule
Africa & Urban & Nairobi & 1.29°--1.19°S & 36.82°--36.92°E \\
       & Rural & Kenyan Savanna & 2.15°--2.05°S & 37.31°--37.41°E \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Urban-Rural Classification}

To ensure accurate labeling of locations as urban or rural, we employ the Global Urban Areas dataset~\cite{schneider2010new}, which provides comprehensive polygon boundaries for urban areas worldwide. For each randomly generated coordinate, we perform a spatial intersection test to determine its classification:

\begin{equation}
\text{Urban}(p) = \begin{cases}
1 & \text{if } p \in \bigcup_{i} U_i \\
0 & \text{otherwise}
\end{cases}
\end{equation}

where $p$ represents a coordinate point and $U_i$ denotes the $i$-th urban area polygon from the Global Urban Areas dataset. This automated classification ensures consistent and objective urban-rural labeling across all geographical regions.

\subsection{Multi-Modal Data Acquisition}

Our data acquisition pipeline consists of three main components: \textit{coordinate generation}, \textit{outdoor location validation}, and \textit{multi-modal image retrieval}.

\subsubsection{Coordinate Generation and Validation}

For each sampling region, we generate random coordinates within the specified geographical boundaries using uniform sampling. Each coordinate undergoes a validation process to ensure data quality:

\begin{enumerate}
    \item \textbf{Urban-Rural Consistency}: Verify that the generated coordinate matches the intended environment type (urban/rural) using the spatial intersection described above.
    \item \textbf{Street View Availability}: Query the Google Street View Metadata API to confirm image availability at the location.
    \item \textbf{Outdoor Location Filtering}: Apply our outdoor detection algorithm to exclude indoor environments.
\end{enumerate}

\subsubsection{Outdoor Detection Algorithm}

To ensure our dataset captures genuine outdoor environments, we implement a robust filtering mechanism that leverages Google Places API data. Our algorithm evaluates each location using the following criteria:

\begin{algorithm}[t]
\caption{Outdoor Location Detection}
\label{alg:outdoor_detection}
\begin{algorithmic}[1]
\Require Street View metadata $M$, Google Maps client $G$
\Ensure Boolean indicating outdoor location
\If{$M.\mathrm{status} \neq \mathrm{OK}$}
    \State \Return False
\EndIf
\If{$M.\mathrm{place\_id}$ is undefined}
    \State \Return True \Comment{Assume outdoor for street-level locations}
\EndIf
\State $\mathrm{details} \gets G.\mathrm{place}(M.\mathrm{place\_id})$
\State $\mathrm{types} \gets \mathrm{details.result.types}$
\State $\mathrm{indoor\_types} \gets \{\mathrm{shopping\_mall}, \mathrm{store}, \mathrm{restaurant}, \mathrm{hospital}, \ldots\}$
\If{$\mathrm{types} \cap \mathrm{indoor\_types} \neq \emptyset$}
    \State \Return False
\Else
    \State \Return True
\EndIf
\end{algorithmic}
\end{algorithm}

This approach is more nuanced than simple keyword filtering, as it distinguishes between genuinely indoor locations (e.g., shopping malls, restaurants) and outdoor points of interest (e.g., parks, monuments) that may also carry establishment tags.

\subsubsection{Image Acquisition and Processing}

For each validated coordinate, we acquire two types of imagery:

\paragraph{Satellite Imagery} We retrieve high-resolution satellite images using the Google Static Maps API with the following specifications:
\begin{itemize}
    \item Resolution: 640x640 pixels
    \item Zoom level: 18 (approximately 1.19 meters/pixel)
    \item Map type: Satellite view
    \item Format: JPEG
\end{itemize}

\paragraph{Street View Imagery} We collect street-view images from four cardinal directions (0°, 90°, 180°, 270°) to provide comprehensive ground-level perspective. Each image has:
\begin{itemize}
    \item Resolution: 640x640 pixels
    \item Field of view: Default Google Street View settings
    \item Format: JPEG
\end{itemize}

The four directional images are horizontally concatenated to create a panoramic representation, resulting in a 2560x640 pixel stitched image that captures the complete ground-level environment.

\subsection{Quality Assurance and Error Handling}

Our data acquisition pipeline implements robust error handling and quality assurance mechanisms:

\subsubsection{Network Resilience}
We employ an exponential backoff retry strategy for API requests, with up to 3 retry attempts for failed connections. This approach handles temporary network issues and API rate limiting gracefully.

\subsubsection{Coordinate Correction}
The Google Street View API may return imagery from coordinates slightly different from the requested location due to road network constraints. We handle this by:
\begin{enumerate}
    \item Recording both original and corrected coordinates
    \item Using corrected coordinates for file naming and deduplication
    \item Ensuring consistent satellite-street view pairing
\end{enumerate}

\subsubsection{Resume Capability}
Our pipeline supports interruption and resumption, checking for existing complete image sets before processing each location. A complete set consists of:
\begin{itemize}
    \item One satellite image
    \item Four directional street view images (0°, 90°, 180°, 270°)
    \item One stitched panoramic image
\end{itemize}

\subsection{Dataset Statistics and Validation}

Throughout the data collection process, we maintain comprehensive statistics including:
\begin{itemize}
    \item Success and failure rates per continent and environment type
    \item API call counts and timing information
    \item Error categorization (metadata failures, download failures, indoor rejections)
    \item Coordinate generation efficiency metrics
\end{itemize}

These statistics are automatically compiled into detailed reports (both human-readable and machine-readable formats) that facilitate dataset validation and quality assessment.

The resulting CVGlobal dataset provides a balanced, geographically diverse collection of paired satellite and street-view imagery suitable for training and evaluating computer vision models across varied global contexts.